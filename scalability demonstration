# Spark partitions (shows distributed processing)
df_clean.rdd.getNumPartitions()
